## SVM 和 Softmax 中损失函数的计算差异

我们看这样一个例子：有两个不同的评分函数值向量
``` matlab
s1 = [10 9 9];
s2 = [10 -10 -10];
```
* 如果我们设置`delta = 1`，正确类别是第一类`yi = 0`，那么对于`s1` `s2`，由于正确分类和错误分类之间的距离已经满足了边界值**1**，那么对于`s1` `s2` 计算出的`loss1 = 0`并且`loss2 = 0`。所以 SVM 分类器只要边界满足就满意了，不会超过限制得去操作具体的分数。
* 但是对于 Softmax 的损失函数，情况则不同。我们可以计算出每个预测分类归一化的概率值：
    ``` matlab
    val_exp1 = exp(s1);
    val_exp2 = exp(s2);
    probability1 = val_exp1 ./ sum(val_exp1);
    probability2 = val_exp2 ./ sum(val_exp2);
    ```
    我们可以得到由`s1` `s2` 计算出来的概率值
    ``` matlab
    probability1 = [ 0.57612   0.21194   0.21194]
    probability2 = [0.9999999958777   0.0000000020612   0.0000000020612]
    ```
    进一步可以得到这两个样本的损失值
    ``` matlab
    loss1 = 0.55144;
    loss2 = 0.0000000041223;
    ```
    `loss2`的值明显要比`loss1`小，从而对于 Softmax 分类器来说这种评分函数更好。但对于 SVM 来说这两种分类器的效果是一样的。
